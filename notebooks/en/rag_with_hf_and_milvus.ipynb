{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/422171/transformers/blob/main/notebooks/en/rag_with_hf_and_milvus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jPDNbbMWhpT"
      },
      "source": [
        "# Build RAG with Hugging Face and Milvus\n",
        "\n",
        "_Authored by: [Chen Zhang](https://github.com/zc277584121)_\n",
        "\n",
        "\n",
        "[Milvus](https://milvus.io/) is a popular open-source vector database that powers AI applications with highly performant and scalable vector similarity search. In this tutorial, we will show you how to build a RAG (Retrieval-Augmented Generation) pipeline with Hugging Face and Milvus.\n",
        "\n",
        "The RAG system combines a retrieval system with an LLM. The system first retrieves relevant documents from a corpus using Milvus vector database, then uses an LLM hosted in Hugging Face to generate answers based on the retrieved documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "m7Qxg8oCWhpT"
      },
      "source": [
        "## Preparation\n",
        "### Dependencies and Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OccIkOhcWhpU",
        "outputId": "4581b4dd-d982-4593-b673-6265b28e543f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (75.2.0)\n",
            "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus)\n",
            "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (5.29.4)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from pymilvus)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.2.2)\n",
            "Collecting milvus-lite>=2.4.0 (from pymilvus)\n",
            "  Downloading milvus_lite-2.4.12-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.24)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading pymilvus-2.5.6-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading milvus_lite-2.4.12-py3-none-manylinux2014_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: ujson, python-dotenv, pypdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, milvus-lite, marshmallow, httpx-sse, grpcio, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, pymilvus, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, sentence-transformers, langchain_community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.30.1\n",
            "    Uninstalling huggingface-hub-0.30.1:\n",
            "      Successfully uninstalled huggingface-hub-0.30.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.4.1\n",
            "    Uninstalling sentence-transformers-3.4.1:\n",
            "      Successfully uninstalled sentence-transformers-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires grpcio>=1.71.0, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 grpcio-1.67.1 httpx-sse-0.4.0 huggingface-hub-0.30.2 langchain_community-0.3.21 marshmallow-3.26.1 milvus-lite-2.4.12 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.8.1 pymilvus-2.5.6 pypdf-5.4.0 python-dotenv-1.1.0 sentence-transformers-4.0.2 typing-inspect-0.9.0 ujson-5.10.0\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade pymilvus sentence-transformers huggingface-hub langchain_community langchain-text-splitters pypdf tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "oCq6WKGUWhpU"
      },
      "source": [
        "> If you are using Google Colab, to enable the dependencies, you may need to **restart the runtime** (click on the \"Runtime\" menu at the top of the screen, and select \"Restart session\" from the dropdown menu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "fwTd8qY0WhpU"
      },
      "source": [
        "In addition, we recommend that you configure your [Hugging Face User Access Token](https://huggingface.co/docs/hub/security-tokens), and set it in your environment variables because we will use a LLM from the Hugging Face Hub. You may get a low limit of requests if you don't set the token environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4bPZhj-WhpU",
        "outputId": "a5c5420b-e8bc-4239-a487-6b89d2f498fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import getpass\n",
        "\n",
        "# enter API key\n",
        "os.environ[\"HF_TOKEN\"] = HF_API_KEY = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUHrokeZWhpV"
      },
      "source": [
        "### Prepare the data\n",
        "\n",
        "We use the [AI Act PDF](https://artificialintelligenceact.eu/wp-content/uploads/2021/08/The-AI-Act.pdf), a regulatory framework for AI with different risk levels corresponding to more or less regulation, as the private knowledge in our RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "0qFOgf_UWhpV"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "\n",
        "# if [ ! -f \"The-AI-Act.pdf\" ]; then\n",
        "#     wget -q https://artificialintelligenceact.eu/wp-content/uploads/2021/08/The-AI-Act.pdf\n",
        "# fi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# https://drive.google.com/file/d/1oiJk3wH0TVJvnPfG9nsZT7uFt0f2jJ_s/view?usp=sharing\n",
        "if [ ! -f \"Powerless-Book.pdf\" ]; then\n",
        "    wget -q -O Powerless-Book.pdf \"https://drive.google.com/uc?export=download&id=1oiJk3wH0TVJvnPfG9nsZT7uFt0f2jJ_s\"\n",
        "fi"
      ],
      "metadata": {
        "id": "7koojCUYekW8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bt1GQHvWhpV"
      },
      "source": [
        "We use the [`PyPDFLoader`](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/) from LangChain to extract the text from the PDF, and then split the text into smaller chunks. By default, we set the chunk size as 1000 and the overlap as 200, which means each chunk will nearly have 1000 characters and the overlap between two chunks will be 200 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JFyjyqHWhpV",
        "outputId": "91b8b2d8-35b8-4a2a-96d9-e292299c0701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "496\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# loader = PyPDFLoader(\"The-AI-Act.pdf\")\n",
        "loader = PyPDFLoader(\"Powerless-Book.pdf\")\n",
        "docs = loader.load()\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "P2lQeDY7WhpW"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mP361SonWhpW"
      },
      "outputs": [],
      "source": [
        "text_lines = [chunk.page_content for chunk in chunks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Jy1P7RWhpW"
      },
      "source": [
        "### Prepare the Embedding Model\n",
        "Define a function to generate text embeddings. We use [BGE embedding model](https://huggingface.co/BAAI/bge-small-en-v1.5) as an example, but you can use any embedding models, such as those found on the [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OvDE9mGpWhpW"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "def emb_text(text):\n",
        "    return embedding_model.encode([text], normalize_embeddings=True).tolist()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHteuNohWhpW"
      },
      "source": [
        "Generate a test embedding and print its dimension and first few elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlQOtxo7WhpW",
        "outputId": "937e93d0-041f-42e9-de42-54ce88612652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n",
            "[-0.07660680264234543, 0.02531672641634941, 0.012505538761615753, 0.004595162346959114, 0.02577998675405979, 0.038167111575603485, 0.08050814270973206, 0.0030353872571140528, 0.024392176419496536, 0.004880355205386877]\n"
          ]
        }
      ],
      "source": [
        "test_embedding = emb_text(\"This is a test\")\n",
        "embedding_dim = len(test_embedding)\n",
        "print(embedding_dim)\n",
        "print(test_embedding[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTCiOiVWhpW"
      },
      "source": [
        "## Load data into Milvus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e1HAqHyWhpW"
      },
      "source": [
        "### Create the Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nCutmLfuWhpW"
      },
      "outputs": [],
      "source": [
        "from pymilvus import MilvusClient\n",
        "\n",
        "milvus_client = MilvusClient(uri=\"./powerless.db\")\n",
        "\n",
        "collection_name = \"rag_collection\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "T7BjT5-jWhpW"
      },
      "source": [
        "> As for the argument of `MilvusClient`:\n",
        "> - Setting the `uri` as a local file, e.g.`./hf_milvus_demo.db`, is the most convenient method, as it automatically utilizes [Milvus Lite](https://milvus.io/docs/milvus_lite.md) to store all data in this file.\n",
        "> - If you have a large amount of data, say more than a million vectors, you can set up a more performant Milvus server on [Docker or Kubernetes](https://milvus.io/docs/quickstart.md). In this setup, please use the server uri, e.g.`http://localhost:19530`, as your `uri`.\n",
        "> - If you want to use [Zilliz Cloud](https://zilliz.com/cloud), the fully managed cloud service for Milvus, adjust the `uri` and `token`, which correspond to the [Public Endpoint and Api key](https://docs.zilliz.com/docs/on-zilliz-cloud-console#cluster-details) in Zilliz Cloud.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WFrZEj_WhpX"
      },
      "source": [
        "Check if the collection already exists and drop it if it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2d1X62RdWhpX"
      },
      "outputs": [],
      "source": [
        "if milvus_client.has_collection(collection_name):\n",
        "    milvus_client.drop_collection(collection_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziHti9N4WhpX"
      },
      "source": [
        "Create a new collection with specified parameters.\n",
        "\n",
        "If we don't specify any field information, Milvus will automatically create a default `id` field for primary key, and a `vector` field to store the vector data. A reserved JSON field is used to store non-schema-defined fields and their values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OSakGN6eWhpX"
      },
      "outputs": [],
      "source": [
        "milvus_client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    dimension=embedding_dim,\n",
        "    metric_type=\"IP\",  # Inner product distance\n",
        "    consistency_level=\"Strong\",  # Strong consistency level\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sik9W_TBWhpX"
      },
      "source": [
        "### Insert data\n",
        "Iterate through the text lines, create embeddings, and then insert the data into Milvus.\n",
        "\n",
        "Here is a new field `text`, which is a non-defined field in the collection schema. It will be automatically added to the reserved JSON dynamic field, which can be treated as a normal field at a high level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E85Q2iddWhpX",
        "outputId": "1df116a4-22c9-4348-ea6f-89efe5eaa071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating embeddings: 100%|██████████| 1276/1276 [00:15<00:00, 80.03it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1276"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "data = []\n",
        "\n",
        "for i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n",
        "    data.append({\"id\": i, \"vector\": emb_text(line), \"text\": line})\n",
        "\n",
        "insert_res = milvus_client.insert(collection_name=collection_name, data=data)\n",
        "insert_res[\"insert_count\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn3xTLyTWhpX"
      },
      "source": [
        "## Build RAG\n",
        "\n",
        "### Retrieve data for a query\n",
        "\n",
        "Let's specify a question to ask about the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IoyeHLqBWhpX"
      },
      "outputs": [],
      "source": [
        "question = \"How does Kai feel about Paedyn and his brother dancing?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lprK21kVWhpX"
      },
      "source": [
        "Search for the question in the collection and retrieve the top 3 semantic matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ufq1jRFnWhpX"
      },
      "outputs": [],
      "source": [
        "search_res = milvus_client.search(\n",
        "    collection_name=collection_name,\n",
        "    data=[\n",
        "        emb_text(question)\n",
        "    ],  # Use the `emb_text` function to convert the question to an embedding vector\n",
        "    limit=3,  # Return top 3 results\n",
        "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
        "    output_fields=[\"text\"],  # Return the text field\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVUVLaZXWhpX"
      },
      "source": [
        "Let's take a look at the search results of the query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNkAp40iWhpX",
        "outputId": "ad66531a-dd03-4517-ec60-0388293adc6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    [\n",
            "        \"him as he says, \\u201cDance with me, will you? Please?\\u201d\\nPaedyn hesitates for only a moment before nodding. And then I\\u2019m\\nstaring after them as they stride onto the dance floor where several other\\ncouples have begun spinning in time to the music.\\nBlair is suddenly saying something to me, dragging me to my feet\\nbefore dragging me onto the dance floor. I don\\u2019t remember when we started\\ndancing. Suddenly, she\\u2019s in my arms, and we are spinning across the marble\\nfloor. The feel of her is foreign to me after the nights spent with Paedyn in\\nmy arms. Nights that I still haven\\u2019t told Kitt about.\\nI was doing him a favor.  \\nMy eyes wander across the dance floor, landing on my brother and the\\ngirl in his arms. I\\u2019m not wearing green, but I feel it, nonetheless. Envy\\nclaws at me as I watch them step in time to the very waltz I led Paedyn\\nthrough only last night. She looks elegant, enticing, entrancing.\\nWhat the hell is wrong with me?\\nI turn away from their spinning forms, angry with myself for feeling.\",\n",
            "        0.7420423030853271\n",
            "    ],\n",
            "    [\n",
            "        \"of the smooth waltz that follows is not. Kai turns around, casually\\nunbuttoning half his shirt and sending my eyes searching for anything to\\nstare at other than his tanned chest and swirling tattoo.\\nAnd then he\\u2019s suddenly before me, surveying me from head to toe with\\na slight smile that displays the deeper dimple on his right cheek. His stare is\\nlike a caress, and he takes his time. I refuse to squirm under that piercing\\ngaze, knowing how he would love to watch me fidget.\\nNot wanting to be outdone, I drag my eyes over his strong facial\\nfeatures and even stronger body beneath. Everything about him is lethal.\\nThat smile. Those eyes. That cunning mind of his.\\n\\u201cAre you sure you\\u2019ll be able to focus on dancing, or will I be too much\\nof a distraction, darling?\\u201d\\nHis words startle me, and my eyes shoot back to his. I huff. \\u201cI think I\\u2019ll\\nmanage, thanks.\\u201d\\nHe gives me a doubtful look. \\u201cI guess we will find out, won\\u2019t we?\\u201d I\\nexpect him to reach out and pull me into a dance, and the thought has my\",\n",
            "        0.7395920753479004\n",
            "    ],\n",
            "    [\n",
            "        \"He holds his hands up and takes a mocking step back before turning to\\nhead down the hall once again. As we continue walking, the question I\\u2019ve\\nbeen waiting to ask finally slips past my lips. \\u201cWhy are you doing this?\\u201d\\nKai halts in front of me. He turns slowly, looking almost amused by the\\nquestion. \\u201cIt\\u2019s simple, really. You\\u2019re attending this ball with my brother, and\\nhe needs to look the best he is able.\\u201d\\nI study his face, stare as a sliver of his mask cracks, displaying all the\\nlove and devotion for his brother, all the lengths he is willing to go for him.\\nIt\\u2019s as if he has a duty to fulfill, as if he is already the Enforcer and this is\\nfar bigger than just stopping me from stepping on his brother\\u2019s toes.\\nAnd then his mask is suddenly back up, and I\\u2019m staring at that cool face\\nonce again, void of the emotion once there. When I can\\u2019t think of a retort, I\\nbegin walking instead. We make a right down a smaller corridor and head to\",\n",
            "        0.7372517585754395\n",
            "    ]\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "retrieved_lines_with_distances = [\n",
        "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
        "]\n",
        "print(json.dumps(retrieved_lines_with_distances, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zUE26KLWhpX"
      },
      "source": [
        "### Use LLM to get an RAG response\n",
        "\n",
        "Before composing the prompt for LLM, let's first flatten the retrieved document list into a plain string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "as1j88P3WhpX"
      },
      "outputs": [],
      "source": [
        "context = \"\\n\".join(\n",
        "    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fngqcyCFWhpX"
      },
      "source": [
        "Define prompts for the Language Model. This prompt is assembled with the retrieved documents from Milvus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "xYQUn1TqWhpX"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"\n",
        "Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT3ly3ZNWhpX"
      },
      "source": [
        "We use the [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) hosted on Hugging Face inference server to generate a response based on the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e8VIIZA1WhpY"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "\n",
        "llm_client = InferenceClient(model=repo_id, timeout=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "JUjPpZqSWhpY"
      },
      "source": [
        "Finally, we can format the prompt and generate the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CfdfCgqgWhpc"
      },
      "outputs": [],
      "source": [
        "prompt = PROMPT.format(context=context, question=question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Qx_R4xWhpc",
        "outputId": "225b2b70-71f9-4213-9f3c-4a370cdb4c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kai feels a sense of duty and devotion towards his brother, and he wants to ensure that his brother looks his best at the ball. He is willing to go to great lengths to fulfill this duty, including ensuring that Paedyn and his brother have a successful dance together.\n"
          ]
        }
      ],
      "source": [
        "answer = llm_client.text_generation(\n",
        "    prompt,\n",
        "    max_new_tokens=1000,\n",
        ").strip()\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1eMt_UC_Whpc"
      },
      "source": [
        "Congratulations! You have built an RAG pipeline with Hugging Face and Milvus."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How does Kai feel about Paedyn and his brother dancing? Does he feel jealous?\""
      ],
      "metadata": {
        "id": "ojLYY1pcjclH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_res = milvus_client.search(\n",
        "    collection_name=collection_name,\n",
        "    data=[\n",
        "        emb_text(question)\n",
        "    ],  # Use the `emb_text` function to convert the question to an embedding vector\n",
        "    limit=3,  # Return top 3 results\n",
        "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
        "    output_fields=[\"text\"],  # Return the text field\n",
        ")"
      ],
      "metadata": {
        "id": "KPApdvLwjm6v"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "retrieved_lines_with_distances = [\n",
        "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
        "]\n",
        "print(json.dumps(retrieved_lines_with_distances, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjIfNgVpjqSJ",
        "outputId": "87d15608-b7ec-49da-a2fe-4e07f965d7c1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    [\n",
            "        \"Chapter Fifty-One\\nPaedyn\\nI\\u2019 M  AVOIDING  HIM . N OT  THE  BEST  WAY  TO  DEAL  WITH  A  PROBLEM , I\\u2019 LL\\nadmit. But Kai is a very pressing problem. A very desirable distraction.\\nSo, I keep myself busy, though I still manage to notice that he is doing\\nthe same. Girl after gorgeous girl finds their way into his arms and onto the\\ndance floor, all of them wearing glowing smiles and green dresses.\\nI bury the emotion I don\\u2019t want to identify as jealousy, though it claws\\nat me nonetheless.\\nI have a job to do.\\nI turn my attention back to my partner for the dozenth time. Kitt smiles,\\ncontinuing our easy conversation that my mind keeps wanting to wander\\nfrom. I force myself to focus on his words rather than the thing I need to\\nsteal from him. We spin, and I catch a glimpse of the keyring against the\\ninside of his suit coat pocket. My fingers twitch, itching to tap into the\\nthieving instincts I\\u2019ve suppressed while in the castle\\u2014for the most part.\\n\\u201cYou look beautiful.\\u201d\",\n",
            "        0.7858374118804932\n",
            "    ],\n",
            "    [\n",
            "        \"him as he says, \\u201cDance with me, will you? Please?\\u201d\\nPaedyn hesitates for only a moment before nodding. And then I\\u2019m\\nstaring after them as they stride onto the dance floor where several other\\ncouples have begun spinning in time to the music.\\nBlair is suddenly saying something to me, dragging me to my feet\\nbefore dragging me onto the dance floor. I don\\u2019t remember when we started\\ndancing. Suddenly, she\\u2019s in my arms, and we are spinning across the marble\\nfloor. The feel of her is foreign to me after the nights spent with Paedyn in\\nmy arms. Nights that I still haven\\u2019t told Kitt about.\\nI was doing him a favor.  \\nMy eyes wander across the dance floor, landing on my brother and the\\ngirl in his arms. I\\u2019m not wearing green, but I feel it, nonetheless. Envy\\nclaws at me as I watch them step in time to the very waltz I led Paedyn\\nthrough only last night. She looks elegant, enticing, entrancing.\\nWhat the hell is wrong with me?\\nI turn away from their spinning forms, angry with myself for feeling.\",\n",
            "        0.7806982398033142\n",
            "    ],\n",
            "    [\n",
            "        \"of the smooth waltz that follows is not. Kai turns around, casually\\nunbuttoning half his shirt and sending my eyes searching for anything to\\nstare at other than his tanned chest and swirling tattoo.\\nAnd then he\\u2019s suddenly before me, surveying me from head to toe with\\na slight smile that displays the deeper dimple on his right cheek. His stare is\\nlike a caress, and he takes his time. I refuse to squirm under that piercing\\ngaze, knowing how he would love to watch me fidget.\\nNot wanting to be outdone, I drag my eyes over his strong facial\\nfeatures and even stronger body beneath. Everything about him is lethal.\\nThat smile. Those eyes. That cunning mind of his.\\n\\u201cAre you sure you\\u2019ll be able to focus on dancing, or will I be too much\\nof a distraction, darling?\\u201d\\nHis words startle me, and my eyes shoot back to his. I huff. \\u201cI think I\\u2019ll\\nmanage, thanks.\\u201d\\nHe gives me a doubtful look. \\u201cI guess we will find out, won\\u2019t we?\\u201d I\\nexpect him to reach out and pull me into a dance, and the thought has my\",\n",
            "        0.7677767276763916\n",
            "    ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PROMPT.format(context=context, question=question)"
      ],
      "metadata": {
        "id": "Cf5AmfTxju6w"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm_client.text_generation(\n",
        "    prompt,\n",
        "    max_new_tokens=1000,\n",
        ").strip()\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aPcNZAHjzUG",
        "outputId": "fa1433e5-2639-4348-e9ab-6158e4df0c10"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kai does not feel jealous about Paedyn and his brother dancing. Instead, he feels a sense of duty to ensure that his brother looks his best at the ball. He is willing to go to great lengths to fulfill this duty, including dancing with the protagonist himself to distract her from his brother. This is evident when he states, \"You're attending this ball with my brother, and he needs to look the best he is able.\" Additionally, when the protagonist asks him why he is doing this, Kai responds by saying that it is simple and that his brother needs to look his best. Therefore, Kai's actions and words suggest that he is focused on supporting his brother rather than feeling jealous or competitive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What does Kai say to Paedyn in the rain?\"\n",
        "search_res = milvus_client.search(\n",
        "    collection_name=collection_name,\n",
        "    data=[\n",
        "        emb_text(question)\n",
        "    ],  # Use the `emb_text` function to convert the question to an embedding vector\n",
        "    limit=3,  # Return top 3 results\n",
        "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
        "    output_fields=[\"text\"],  # Return the text field\n",
        ")\n",
        "\n",
        "retrieved_lines_with_distances = [\n",
        "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
        "]\n",
        "print(json.dumps(retrieved_lines_with_distances, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyohJqUEkJhY",
        "outputId": "c3b89a84-847d-41c8-bd7a-ec1dce02a2f1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    [\n",
            "        \"adorable as you looked blinking up at me in the rain, I want you to see me\\nclearly when I tell you this.\\u201d\\nThere goes that stupid flutter in my chest.\\n\\u201cI meant what I said. I can\\u2019t take my eyes off you. I can\\u2019t take my mind\\noff you.\\u201d\\nI look away from his burning gaze, shaking my head as I mutter, \\u201cKai, I\\n\\u2014\\u201d\\n\\u201cPaedyn.\\u201d\\nI still. I shiver. He says my name like it\\u2019s sacred, like it\\u2019s an oath he\\u2019s\\nswearing.\\nHe tilts his head to the side, eyes roaming over my face. \\u201cTell me,\\u201d he\\nmurmurs, \\u201cwhat do you want me to call you?\\u201d\\nMy eyes slowly meet his, confused by his question. \\u201cWhat do you want\\nto call me?\\u201d\\n\\u201cI want to call you mine.\\u201d\\nWe stare at each other. Both of us breathing hard, both of us taking in\\nthe other. The rain is still splattering Kai, clinging to his thick lashes and\\ndripping from his jaw.\\n\\u201cI know you feel it too,\\u201d he says quietly.\\n\\u201cFeel what?\\u201d\\n\\u201cFeel alive. Feel on fire. Feel.\\u201d There is an intensity in his eyes, his\",\n",
            "        0.775370180606842\n",
            "    ],\n",
            "    [\n",
            "        \"him in the world that is beginning to fade.\\n\\u201cPaedyn.\\u201d Kai\\u2019s voice is so far away, so distant from where I\\u2019m slipping\\ninto oblivion. \\u201cPaedyn, open your eyes.\\u201d It\\u2019s an order, strong and stern. And\\nI ignore it. How very typical of me. Even in death my body refuses to listen\\nto the commands of the future Enforcer. \\u201cOpen your eyes, dammit!\\u201d\\nTired. I\\u2019m so very tired.\\nFar, far away, I hear a male voice muttering panicked words.\\n\\u201cIf you die, I\\u2019m going to kill you.\\u201d\\nOceanofPDF.com\",\n",
            "        0.7555992603302002\n",
            "    ],\n",
            "    [\n",
            "        \"His voice strains with emotion. \\u201cRun, Paedyn. Because when I catch you, I\\nwill not miss. I will not falter. I will not make the mistake of feeling for\\nyou.\\u201d\\nI\\u2019m frozen, still standing in the freezing rain.\\n\\u201cGo!\\u201d he yells, his voice breaking. \\u201cGo before I find someone who isn\\u2019t\\na coward, someone who isn\\u2019t a fool, and let them bury this dagger in your\\nback right here, right now.\\u201d\\nI stumble, tripping over uneven ground before turning away from him.\\nAnd then I\\u2019m running again like I\\u2019ve found myself doing all day, all my\\nlife. I throw a glance over my shoulder, glimpsing Kai dropping to his\\nknees beside the king with his eyes trained on me.\\nI swallow the emotions clawing their way up my throat, threatening to\\nleak from my stinging eyes.\\nI don\\u2019t look back.\\nOceanofPDF.com\",\n",
            "        0.7545690536499023\n",
            "    ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PROMPT.format(context=context, question=question)\n",
        "answer = llm_client.text_generation(\n",
        "    prompt,\n",
        "    max_new_tokens=1000,\n",
        ").strip()\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkkXQhPwkbPl",
        "outputId": "ec5f1708-624b-453d-8aed-af408c2f09cd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kai does not say anything to Paedyn in the rain in the provided context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-b9PVgYksMR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}